{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as ks\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"dataset_path\": \"images/\",\n",
    "    \"validation_ratio\": 0.2,\n",
    "    \"image_size\": (300, 300),\n",
    "    \"input_shape\": (300, 300, 3),\n",
    "    \"batch_size\": 32,\n",
    "    \"mode\": \"train\",\n",
    "    \"loss_function\": \"categorical_crossentropy\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"epochs\": 8,\n",
    "    \"dropout\": 0.15,\n",
    "    \"backbone_train\": False,\n",
    "    \"checkpoint_pattern\": \"checkpoint/inception-v4/cp-{epoch:03d}-dropout.ckpt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train/test 데이터셋 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_image.loader import image_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리 과정 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_image.preprocess import preprocess\n",
    "from prep_image.preprocess import normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(config):\n",
    "    print('system >> creating a model...')\n",
    "    model = define_model(config)\n",
    "    mode = config['mode']\n",
    "\n",
    "    if mode in [\"retrain\", \"test\"]:\n",
    "        print('system >> loading pretrained model...', config['saved_model'])\n",
    "        model.load_weights(config['saved_model'])\n",
    "        \n",
    "    model.compile(loss=config['loss_function'], optimizer=config['optimizer'], metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def define_model(config):\n",
    "    incep_rv2 = InceptionResNetV2(weights='imagenet', include_top=False)\n",
    "    incep_rv2.trainable = config[\"backbone_train\"]\n",
    "    \n",
    "    classifier = ks.models.Sequential([\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(config['dropout']),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model = ks.models.Sequential([\n",
    "        normalizer(config['input_shape']),\n",
    "        incep_rv2,\n",
    "        classifier\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 콜백 작성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(ks.callbacks.Callback):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.t_loss = {}\n",
    "        self.t_acc = {}\n",
    "        self.v_loss = {}\n",
    "        self.v_acc = {}\n",
    "        self.step = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.v_loss[self.step] = logs['val_loss']\n",
    "        self.v_acc[self.step] = logs['val_accuracy']\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.t_acc[self.step] = logs['accuracy']\n",
    "        self.t_loss[self.step] = logs['loss']\n",
    "        self.step += 1\n",
    "\n",
    "    def on_train_end(self, logs):\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, (loss_ax, acc_ax) = plt.subplots(2, 1)\n",
    "        \n",
    "        loss_ax.plot(self.t_loss.keys(), self.t_loss.values(), label='training loss')\n",
    "        loss_ax.plot(self.v_loss.keys(), self.v_loss.values(), label='validation loss')\n",
    "        loss_ax.set_xlabel('Steps')\n",
    "        loss_ax.set_ylabel('Loss')\n",
    "        \n",
    "        acc_ax.plot(self.t_acc.keys(), self.t_acc.values(), label='training acc')\n",
    "        acc_ax.plot(self.v_acc.keys(), self.v_acc.values(), label='validation acc')\n",
    "        acc_ax.set_xlabel('Steps')\n",
    "        acc_ax.set_ylabel('Accuracy')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "recorder = CustomCallback()\n",
    "checkpoint_callback = ks.callbacks.ModelCheckpoint(\n",
    "    filepath=config[\"checkpoint_pattern\"], \n",
    "    verbose=1,\n",
    "    monitor='val_accuracy',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습과 테스트 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    model = create_model(config)\n",
    "    print('system >> model summary')\n",
    "    model.summary()\n",
    "    \n",
    "    if config['mode'] in ['train', 'retrain']:\n",
    "        hist = do_train(model, config)\n",
    "        do_eval(model, config)\n",
    "    else:\n",
    "        do_eval(model, config)\n",
    "        \n",
    "    return hist\n",
    "\n",
    "def do_train(model, config):\n",
    "    shape = (config['batch_size'], *config['input_shape'])\n",
    "    train_ds, valid_ds = image_loader(config['dataset_path'], config['validation_ratio'], \n",
    "                                  config['image_size'], config['batch_size'])\n",
    "    print('system >> identified classes:', *train_ds.class_names)\n",
    "    \n",
    "    train_ds = preprocess(train_ds, shape=shape, shuffle=True, augment=True)\n",
    "    valid_ds = preprocess(valid_ds, shape=shape)\n",
    "    print('system >> training begins...')\n",
    "    return model.fit(train_ds, \n",
    "          validation_data=valid_ds, \n",
    "          epochs=config['epochs'],\n",
    "          callbacks=[recorder, checkpoint_callback])\n",
    "\n",
    "def do_eval(model, config):\n",
    "    shape = (config['batch_size'], *config['image_size'])\n",
    "    valid_ds = image_loader(config['dataset_path'], config['validation_ratio'], \n",
    "                                  config['image_size'], config['batch_size'], subset='valid')\n",
    "    print('system >> identified classes:', *valid_ds.class_names)\n",
    "    \n",
    "    valid_ds = preprocess(valid_ds, shape=shape)\n",
    "    print('system >> evaluation begins...')\n",
    "    model.evaluate(valid_ds)\n",
    "\n",
    "def do_test(model, config):\n",
    "    print('system >> test begins...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system >> creating a model...\n",
      "system >> model summary\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 300, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Functio (None, None, None, 1536)  54336736  \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 3)                 19661603  \n",
      "=================================================================\n",
      "Total params: 73,998,339\n",
      "Trainable params: 19,661,603\n",
      "Non-trainable params: 54,336,736\n",
      "_________________________________________________________________\n",
      "Found 45000 files belonging to 3 classes.\n",
      "Using 36000 files for training.\n",
      "Found 45000 files belonging to 3 classes.\n",
      "Using 9000 files for validation.\n",
      "system >> identified classes: 0food 1interior 2exterior\n",
      "system >> training begins...\n",
      "Epoch 1/8\n",
      "   6/1125 [..............................] - ETA: 3:16 - loss: 25.0657 - accuracy: 0.4830WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0539s vs `on_train_batch_end` time: 0.1018s). Check your callbacks.\n",
      "1125/1125 [==============================] - 365s 237ms/step - loss: 1.5998 - accuracy: 0.8553 - val_loss: 0.2197 - val_accuracy: 0.9248\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.92478, saving model to checkpoint/inception-v4/cp-001-dropout.ckpt\n",
      "Epoch 2/8\n"
     ]
    }
   ],
   "source": [
    "hist = main(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
