{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as ks\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"dataset_path\": \"images/\",\n",
    "    \"validation_ratio\": 0.2,\n",
    "    \"image_size\": (300, 300),\n",
    "    \"input_shape\": (300, 300, 3),\n",
    "    \"batch_size\": 32,\n",
    "    \"mode\": \"train\",\n",
    "    \"loss_function\": \"categorical_crossentropy\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"epochs\": 8,\n",
    "    \"dropout\": 0.0,\n",
    "    \"backbone_train\": False,\n",
    "    \"checkpoint_pattern\": \"checkpoint/inception-v4/cp-{epoch:03d}.ckpt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train/test 데이터셋 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_image.loader import image_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리 과정 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_image.preprocess import preprocess\n",
    "from prep_image.preprocess import normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(config):\n",
    "    print('system >> creating a model...')\n",
    "    model = define_model(config)\n",
    "    mode = config['mode']\n",
    "\n",
    "    if mode in [\"retrain\", \"test\"]:\n",
    "        print('system >> loading pretrained model...', config['saved_model'])\n",
    "        model.load_weights(config['saved_model'])\n",
    "        \n",
    "    model.compile(loss=config['loss_function'], optimizer=config['optimizer'], metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def define_model(config):\n",
    "    incep_rv2 = InceptionResNetV2(weights='imagenet', include_top=False)\n",
    "    incep_rv2.trainable = config[\"backbone_train\"]\n",
    "    \n",
    "    classifier = ks.models.Sequential([\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(config['dropout']),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model = ks.models.Sequential([\n",
    "        normalizer(config['input_shape']),\n",
    "        incep_rv2,\n",
    "        classifier\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 콜백 작성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(ks.callbacks.Callback):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.t_loss = {}\n",
    "        self.t_acc = {}\n",
    "        self.v_loss = {}\n",
    "        self.v_acc = {}\n",
    "        self.step = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.v_loss[self.step] = logs['val_loss']\n",
    "        self.v_acc[self.step] = logs['val_accuracy']\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.t_acc[self.step] = logs['accuracy']\n",
    "        self.t_loss[self.step] = logs['loss']\n",
    "        self.step += 1\n",
    "\n",
    "    def on_train_end(self, logs):\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, (loss_ax, acc_ax) = plt.subplots(2, 1)\n",
    "        fig.subplots_adjust(hspace=0.5)\n",
    "        \n",
    "        loss_ax.plot(self.t_loss.keys(), self.t_loss.values(), label='training loss')\n",
    "        loss_ax.plot(self.v_loss.keys(), self.v_loss.values(), label='validation loss')\n",
    "        loss_ax.set_xlabel('Steps')\n",
    "        loss_ax.set_ylabel('Loss')\n",
    "        \n",
    "        \n",
    "        acc_ax.plot(self.t_acc.keys(), self.t_acc.values(), label='training acc')\n",
    "        acc_ax.plot(self.v_acc.keys(), self.v_acc.values(), label='validation acc')\n",
    "        acc_ax.set_xlabel('Steps')\n",
    "        acc_ax.set_ylabel('Accuracy')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "recorder = CustomCallback()\n",
    "checkpoint_callback = ks.callbacks.ModelCheckpoint(\n",
    "    filepath=config[\"checkpoint_pattern\"], \n",
    "    verbose=1,\n",
    "    monitor='val_accuracy',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습과 테스트 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    model = create_model(config)\n",
    "    print('system >> model summary')\n",
    "    model.summary()\n",
    "    \n",
    "    if config['mode'] in ['train', 'retrain']:\n",
    "        hist = do_train(model, config)\n",
    "        do_eval(model, config)\n",
    "    else:\n",
    "        do_eval(model, config)\n",
    "        \n",
    "    return hist\n",
    "\n",
    "def do_train(model, config):\n",
    "    shape = (config['batch_size'], *config['input_shape'])\n",
    "    train_ds, valid_ds = image_loader(config['dataset_path'], config['validation_ratio'], \n",
    "                                  config['image_size'], config['batch_size'])\n",
    "    print('system >> identified classes:', *train_ds.class_names)\n",
    "    \n",
    "    train_ds = preprocess(train_ds, shape=shape, shuffle=True, augment=True)\n",
    "    valid_ds = preprocess(valid_ds, shape=shape)\n",
    "    print('system >> training begins...')\n",
    "    return model.fit(train_ds, \n",
    "          validation_data=valid_ds, \n",
    "          epochs=config['epochs'],\n",
    "          callbacks=[recorder, checkpoint_callback])\n",
    "\n",
    "def do_eval(model, config):\n",
    "    shape = (config['batch_size'], *config['image_size'], 3)\n",
    "    valid_ds = image_loader(config['dataset_path'], config['validation_ratio'], \n",
    "                                  config['image_size'], config['batch_size'], subset='valid')\n",
    "    print('system >> identified classes:', *valid_ds.class_names)\n",
    "    \n",
    "    valid_ds = preprocess(valid_ds, shape=shape)\n",
    "    print('system >> evaluation begins...')\n",
    "    model.evaluate(valid_ds)\n",
    "\n",
    "def do_test(model, config):\n",
    "    print('system >> test begins...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system >> creating a model...\n",
      "system >> model summary\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 300, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Functio (None, None, None, 1536)  54336736  \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 3)                 19661603  \n",
      "=================================================================\n",
      "Total params: 73,998,339\n",
      "Trainable params: 19,661,603\n",
      "Non-trainable params: 54,336,736\n",
      "_________________________________________________________________\n",
      "Found 45000 files belonging to 3 classes.\n",
      "Using 36000 files for training.\n",
      "Found 45000 files belonging to 3 classes.\n",
      "Using 9000 files for validation.\n",
      "system >> identified classes: 0food 1interior 2exterior\n",
      "system >> training begins...\n",
      "   6/1125 [..............................] - ETA: 3:13 - loss: 17.2305 - accuracy: 0.4272WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0568s vs `on_train_batch_end` time: 0.0970s). Check your callbacks.\n",
      "1125/1125 [==============================] - 369s 238ms/step - loss: 2.6805 - accuracy: 0.8552 - val_loss: 0.2330 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.92400, saving model to checkpoint/inception-v4/cp-001.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45000 files belonging to 3 classes.\n",
      "Using 9000 files for validation.\n",
      "system >> identified classes: 0food 1interior 2exterior\n",
      "system >> evaluation begins...\n",
      " 85/282 [========>.....................] - ETA: 46s - loss: 0.2221 - accuracy: 0.9287"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-437d98c40d05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-83f0bc959e2f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mode'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'retrain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdo_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdo_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-83f0bc959e2f>\u001b[0m in \u001b[0;36mdo_eval\u001b[0;34m(model, config)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mvalid_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'system >> evaluation begins...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdo_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2970\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2971\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2972\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1946\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1947\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1948\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1949\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1950\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
