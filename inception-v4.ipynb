{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as ks\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"dataset_path\": \"images/\",\n",
    "    \"validation_ratio\": 0.2,\n",
    "    \"image_size\": (300, 300),\n",
    "    \"batch_size\": 32,\n",
    "    \"mode\": \"train\",\n",
    "    \"loss_function\": \"categorical_crossentropy\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"epochs\": 100,\n",
    "    \"dropout\": 0.1,\n",
    "    \"backbone_train\": False,\n",
    "    \"checkpoint_pattern\": \"checkpoint/cp-{epoch:03d}-inc.ckpt\",\n",
    "    \"checkpoint_dir\": \"checkpoint/\",\n",
    "    \"saved_model\": \"checkpoint/cp-007-inc.ckpt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"dataset_path\": \"images/\",\n",
    "    \"validation_ratio\": 0.2,\n",
    "    \"image_size\": (300, 300),\n",
    "    \"batch_size\": 32,\n",
    "    \"mode\": \"test\",\n",
    "    \"loss_function\": \"categorical_crossentropy\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"epochs\": 100,\n",
    "    \"dropout\": 0.0,\n",
    "    \"checkpoint_pattern\": \"checkpoint/cp-{epoch:03d}-inc.ckpt\",\n",
    "    \"checkpoint_dir\": \"checkpoint/\",\n",
    "    \"saved_model\": \"checkpoint/cp-007-inc.ckpt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train/test 데이터셋 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_image.loader import image_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리 과정 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_image.preprocess import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(config):\n",
    "    print('system >> creating a model...')\n",
    "    model = define_model(config)\n",
    "    mode = config['mode']\n",
    "\n",
    "    if mode in [\"retrain\", \"test\"]:\n",
    "        print('system >> loading pretrained model...', config['saved_model'])\n",
    "        model.load_weights(config['saved_model'])\n",
    "        \n",
    "    model.compile(loss=config['loss_function'], optimizer=config['optimizer'], metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def define_model(config):\n",
    "    incep_rv2 = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "    incep_rv2.trainable = False\n",
    "    \n",
    "    classifier = ks.models.Sequential([\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(config['dropout']),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model = ks.models.Sequential([\n",
    "        incep_rv2,\n",
    "        classifier\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 콜백 작성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(ks.callbacks.Callback):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.t_loss = {}\n",
    "        self.t_acc = {}\n",
    "        \n",
    "        self.v_loss = []\n",
    "        self.v_acc = []\n",
    "        self.step = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print('\\n==========\\n')\n",
    "        print('Epoch {} result'.format(epoch))\n",
    "        \n",
    "        print('Training Loss:', logs['loss'])\n",
    "        print('Traininig Accuracy:', logs['accuracy'])\n",
    "        \n",
    "        print('Validation Loss:', logs['val_loss'])\n",
    "        print('Validation Accuracy:', logs['val_accuracy'])\n",
    "        self.v_loss.append(logs['val_loss'])\n",
    "        self.v_acc.append(logs['val_accuracy'])\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.t_acc[self.step] = logs['accuracy']\n",
    "        self.t_loss[self.step] = logs['loss']\n",
    "        self.step += 1\n",
    "\n",
    "    def on_train_end(self, logs):\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.plot(self.t_loss.keys(), self.t_loss.values())\n",
    "        plt.xlabel('Training Steps')\n",
    "        plt.ylabel('Training Loss')\n",
    "        plt.show()\n",
    "\n",
    "        self.t_loss = {}\n",
    "        self.t_acc = {}\n",
    "        \n",
    "recorder = CustomCallback()\n",
    "checkpoint_callback = ks.callbacks.ModelCheckpoint(\n",
    "    filepath=config[\"checkpoint_pattern\"], \n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습과 테스트 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    model = create_model(config)\n",
    "    print('system >> model summary')\n",
    "    model.summary()\n",
    "    \n",
    "    if config['mode'] in ['train', 'retrain']:\n",
    "        do_train(model, config)\n",
    "        do_eval(model, config)\n",
    "    else:\n",
    "        do_eval(model, config)\n",
    "\n",
    "def do_train(model, config):\n",
    "    shape = (config['batch_size'], *config['image_size'], 3)\n",
    "    train_ds, valid_ds = image_loader(config['dataset_path'], config['validation_ratio'], \n",
    "                                  config['image_size'], config['batch_size'])\n",
    "    print('system >> identified classes:', *train_ds.class_names)\n",
    "    \n",
    "    train_ds = preprocess(train_ds, shape=shape, shuffle=True, augment=True)\n",
    "    valid_ds = preprocess(valid_ds, shape=shape)\n",
    "    print('system >> training begins...')\n",
    "    model.fit(train_ds, \n",
    "          validation_data=valid_ds, \n",
    "          epochs=config['epochs'],\n",
    "          callbacks=[recorder, checkpoint_callback])\n",
    "\n",
    "def do_eval(model, config):\n",
    "    shape = (config['batch_size'], *config['image_size'], 3)\n",
    "    valid_ds = image_loader(config['dataset_path'], config['validation_ratio'], \n",
    "                                  config['image_size'], config['batch_size'], subset='valid')\n",
    "    print('system >> identified classes:', *valid_ds.class_names)\n",
    "    \n",
    "    valid_ds = preprocess(valid_ds, shape=shape)\n",
    "    print('system >> evaluation begins...')\n",
    "    model.evaluate(valid_ds)\n",
    "\n",
    "def do_test(model, config):\n",
    "    print('system >> test begins...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system >> creating a model...\n",
      "system >> loading pretrained model... checkpoint/cp-007-inc.ckpt\n",
      "system >> model summary\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Functio (None, 8, 8, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 3)                 19661603  \n",
      "=================================================================\n",
      "Total params: 73,998,339\n",
      "Trainable params: 19,661,603\n",
      "Non-trainable params: 54,336,736\n",
      "_________________________________________________________________\n",
      "Found 45000 files belonging to 3 classes.\n",
      "Using 9000 files for validation.\n",
      "system >> identified classes: exterior food interior\n",
      "system >> evaluation begins...\n",
      "282/282 [==============================] - 54s 170ms/step - loss: 0.1588 - accuracy: 0.9391\n"
     ]
    }
   ],
   "source": [
    "main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
